{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"unstructured[all-docs]\" pillow pydantic lxml matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for pms: \n"
     ]
    }
   ],
   "source": [
    "! sudo apt update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get install libleptonica-dev tesseract-ocr libtesseract-dev python3-pil tesseract-ocr-eng tesseract-ocr-script-latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install unstructured-pytesseract\n",
    "! pip install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/multimodal_rag_project01/bot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements=partition_pdf(\n",
    "    filename=\"/home/pms/llm_project/multimodal_rag_project01/data/cj.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    extract_images_in_pdf=True,\n",
    "    extract_image_block_types=[\"Image\", \"Table\"],\n",
    "    extract_image_block_to_payload=False,\n",
    "    extract_image_block_output_dir=\"extracted_data\",\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Header=[]\n",
    "Footer=[]\n",
    "Title=[]\n",
    "NarrativeText=[]\n",
    "Text=[]\n",
    "ListItem=[]\n",
    "img=[]\n",
    "tab=[]\n",
    "for element in raw_pdf_elements:\n",
    "  if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
    "            Header.append(str(element))\n",
    "  elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
    "            Footer.append(str(element))\n",
    "  elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
    "            Title.append(str(element))\n",
    "  elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
    "            NarrativeText.append(str(element))\n",
    "  elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
    "            Text.append(str(element))\n",
    "  elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
    "            ListItem.append(str(element))\n",
    "  elif \"unstructured.documents.elements.Image\" in str(type(element)):\n",
    "            img.append(str(element))\n",
    "  elif \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tab.append(str(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type your email... Subscribe']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=[]\n",
    "for element in raw_pdf_elements:\n",
    "  if \"unstructured.documents.elements.Image\" in str(type(element)):\n",
    "            img.append(str(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EV/NTM EV/2024 EV/NTM NTMRev Gross Operating FCF % in Top 10 Company Rev Rev FCF Growth Margin Margin Margin Multiple LTM 1 Snowflake 15.5x 13.4x 55x 27% 66% (41%) 25% 100% 2 MongoDB 14.6x 12.9x 133x 17% 74% (18%) 3% 67% 3 Palantir 14.5x 13.9x 58x 19% 80% 2% 22% 47% 4 Cloudflare 13.4x 12.6x 153x 28% 76% (16%) 8% 100% 5 Datadog 13.1x 12.4x 52x 19% 80% (5%) 25% 99% 6 CrowdStrike 12.5x 11.1x 37x 31% 74% (6%) 30% 31% 7 Adobe 12.3x 11.9x 30x 12% 88% 34% 40% 26% 8 ServiceNow 12.2x 11.6x 38x 21% 79% 8% 28% 70% 9 Samsara 11.8x 10.5x 393x 31% 72% (34%) (3%) 72% 10 Zscaler 11.8x 10.5x 48x 27% 78% (14%) 21% 36% Overall Median = 50x. 48x 33.7 18% = 75% = (16%) 8% Clouded Judgement @jaminball ALTIMETER'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements2=partition_pdf(\n",
    "    filename=\"/home/pms/llm_project/multimodal_rag_project01/data2/nlp-tasks-paper.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    extract_images_in_pdf=True,\n",
    "    extract_image_block_types=[\"Image\", \"Table\"],\n",
    "    extract_image_block_to_payload=False,\n",
    "    extract_image_block_output_dir=\"extracted_data2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain\n",
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "config_data = json.load(open(\"./config.json\"))\n",
    "MISTRALAI_API_KEY = config_data[\"MISTRAL_API_KEY\"]\n",
    "GROQ_API_KEY = config_data[\"GROQ_API_KEY\"]\n",
    "os.environ[\"MISTRALAI_API_KEY\"] = MISTRALAI_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llava-v1.5-7b-4096-preview\",\n",
    "    temperature=0.5,\n",
    "    api_key=GROQ_API_KEY,\n",
    "    max_tokens=4096,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pms/llm_project/multimodal_rag_project01/bot/lib/python3.10/site-packages/langchain_mistralai/embeddings.py:175: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "embeddings = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "#from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text elements. \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval.text: {element} \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain = {\"element\": lambda x: x} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries = []\n",
    "text_summaries = summarize_chain.batch(Text,{\"max_concurrency\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '\"10Y\" refers to a 10-year investment, and the return on investment is 4.6%.',\n",
       " 'The given text does not provide any context or information for me to summarize. Please provide a specific text for me to assist with summarizing.',\n",
       " 'The table is titled \"Table of Contents\" and contains information on various topics. The first section is titled \"Introduction\" and provides an overview of the topics covered in the table. The second section is titled \"Topic 1\" and provides a more detailed explanation of the first topic. The third section is titled \"Topic 2\" and provides a similar explanation of the second topic. The table continues in this manner, with each section providing a detailed explanation of a different topic. The table is well-organized and easy to read, making it an effective tool for navigation and understanding the content.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_summaries = []\n",
    "table_summaries = summarize_chain.batch(tab, {\"max_concurrency\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Email address: [type your email here] Subscribe to receive updates and news.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
